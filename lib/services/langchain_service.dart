// lib/services/langchain_service.dart
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:langchain/langchain.dart';
import 'package:langchain_openai/langchain_openai.dart';
import 'dart:convert';
import '../models/conversation_model.dart' as app_models;
import '../models/message_model.dart' as app_models; // app_models prefixë¡œ ë³€ê²½
import 'auth_service.dart';
import 'voice_service.dart';
import 'conversation_service.dart';
import 'package:flutter/foundation.dart';
import 'package:tiiun/services/remote_config_service.dart';

// LangChain ì„œë¹„ìŠ¤ Provider
final langchainServiceProvider = Provider<LangchainService>((ref) {
  final authService = ref.watch(authServiceProvider);
  final voiceService = ref.watch(voiceServiceProvider);
  final conversationService = ref.watch(conversationServiceProvider);
  final remoteConfigService = ref.watch(remoteConfigServiceProvider);
  final openAIapiKey = remoteConfigService.getOpenAIApiKey();
  return LangchainService(authService, voiceService, conversationService, openAIapiKey);
});

class LangchainResponse {
  final String text;
  final String? voiceFileUrl;
  final double? voiceDuration;
  final String? voiceId;
  final String? ttsSource;

  LangchainResponse({
    required this.text,
    this.voiceFileUrl,
    this.voiceDuration,
    this.voiceId,
    this.ttsSource,
  });
}

class LangchainService {
  final AuthService _authService;
  final VoiceService _voiceService;
  final ConversationService _conversationService;
  final String _openAIapiKey; // Store the API key

  ChatOpenAI? _chatModel;

  LangchainService(
    this._authService,
    this._voiceService,
    this._conversationService,
    this._openAIapiKey, // Receive API key
  ) {
    _initializeLangChain();
  }

  // LangChain ì´ˆê¸°í™”
  void _initializeLangChain() {
    if (_openAIapiKey.isNotEmpty) {
      _chatModel = ChatOpenAI(
        apiKey: _openAIapiKey,
        model: 'gpt-4o', // ğŸš€ UPGRADED: gpt-3.5-turbo -> gpt-4o
        temperature: 0.7,
        maxTokens: 1200, // ğŸ”¥ INCREASED: 1000 -> 1200 for better responses
      );
      debugPrint("LangchainService initialized with OpenAI API key.");
    } else {
      debugPrint("LangchainService: OpenAI API key is missing. LLM features will be limited or use dummy responses.");
    }
  }

  // ì‚¬ìš©ì ë©”ì‹œì§€ì— ëŒ€í•œ ì‘ë‹µ ìƒì„±
  Future<LangchainResponse> getResponse({
    required String conversationId,
    required String userMessage,
  }) async {
    try {
      final userId = _authService.getCurrentUserId();
      if (userId == null) {
        return _createDefaultResponse('ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¡œê·¸ì¸ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
      }

      final messagesHistory = await _getConversationHistory(conversationId);
      final user = await _authService.getUserModel(userId);

      // ì‚¬ìš©ìê°€ ì„ íƒí•œ ìŒì„± ID
      String? selectedVoiceId = user.preferredVoice;
      debugPrint('LangchainService: ì‚¬ìš©ì ì„ í˜¸ ìŒì„± ID - $selectedVoiceId');

      // API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œì¸ ê²½ìš° (_chatModel ìœ ë¬´ë¡œ íŒë‹¨)
      if (_chatModel == null || _openAIapiKey.isEmpty) {
        debugPrint("LangchainService: ì±„íŒ… ëª¨ë¸ ì—†ìŒ (API í‚¤ ì—†ìŒ). ë”ë¯¸ ì‘ë‹µ ì‚¬ìš©.");
        final dummyResponse = _getDummyResponse(userMessage);
        try {
          debugPrint('LangchainService: ë”ë¯¸ ì‘ë‹µì— ëŒ€í•œ TTS ìƒì„± ì‹œë„');
          final voiceData = await _voiceService.textToSpeechFile(
            dummyResponse,
            selectedVoiceId
          );

          if (voiceData['url'] == null || (voiceData['url'] as String).isEmpty) {
            debugPrint('LangchainService: TTS URLì´ ë¹„ì–´ìˆìŒ - ì˜¤ë¥˜: ${voiceData['error']}');
            return LangchainResponse(
              text: dummyResponse,
              voiceId: selectedVoiceId,
              ttsSource: 'error',
            );
          }

          debugPrint('LangchainService: ë”ë¯¸ ì‘ë‹µ TTS ì„±ê³µ - URL: ${voiceData['url']}, ì†ŒìŠ¤: ${voiceData['source']}');
          return LangchainResponse(
            text: dummyResponse,
            voiceFileUrl: voiceData['url'] as String?,
            voiceDuration: voiceData['duration'] as double?,
            voiceId: selectedVoiceId,
            ttsSource: voiceData['source'] as String?,
          );
        } catch (e) {
          debugPrint('ìŒì„± ìƒì„± ì˜¤ë¥˜ (dummy response): $e');
          return LangchainResponse(
            text: dummyResponse,
            voiceId: selectedVoiceId,
            ttsSource: 'error',
          );
        }
      }

      // LangChainì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±
      String llmResponseText = '';
      try {
        llmResponseText = await _generateResponseWithLangChain(
          messagesHistory,
          userMessage,
          selectedVoiceId,
        );
        debugPrint('LangchainService: LangChain ì‘ë‹µ ìƒì„± ì„±ê³µ - ê¸¸ì´: ${llmResponseText.length}');
      } catch (e) {
        debugPrint('LangChain ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: $e. Falling back to dummy response.');
        llmResponseText = _getDummyResponse(userMessage);
      }

      try {
        // TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±
        debugPrint('LangchainService: ì‘ë‹µ í…ìŠ¤íŠ¸ì— ëŒ€í•œ TTS íŒŒì¼ ìƒì„± ì‹œë„');
        final voiceData = await _voiceService.textToSpeechFile(
          llmResponseText,
          selectedVoiceId
        );

        if (voiceData['url'] == null || (voiceData['url'] as String).isEmpty) {
          debugPrint('LangchainService: TTS URLì´ ë¹„ì–´ìˆìŒ - ì˜¤ë¥˜: ${voiceData['error']}');
          return LangchainResponse(
            text: llmResponseText,
            voiceId: selectedVoiceId,
            ttsSource: 'error',
          );
        }

        debugPrint('LangchainService: TTS íŒŒì¼ ìƒì„± ì„±ê³µ - URL: ${voiceData['url']}, ì†ŒìŠ¤: ${voiceData['source']}');
        return LangchainResponse(
          text: llmResponseText,
          voiceFileUrl: voiceData['url'] as String?,
          voiceDuration: voiceData['duration'] as double?,
          voiceId: selectedVoiceId,
          ttsSource: voiceData['source'] as String?,
        );
      } catch (e) {
        debugPrint('LangchainService: ìŒì„± ìƒì„± ì˜¤ë¥˜ (LLM response): $e');
        return LangchainResponse(
          text: llmResponseText,
          voiceId: selectedVoiceId,
          ttsSource: 'error',
        );
      }
    } catch (e) {
      debugPrint('LangChain getResponse ì¤‘ ì „ë°˜ì ì¸ ì˜¤ë¥˜ ë°œìƒ: $e');
      return _createDefaultResponse('ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.');
    }
  }

  LangchainResponse _createDefaultResponse(String text) {
    return LangchainResponse(
      text: text,
      voiceId: 'default',
      ttsSource: 'none',
    );
  }

  Future<String> _generateResponseWithLangChain(
    List<app_models.Message> messageHistory, // app_models.Messageë¡œ ëª…ì‹œì  ì‚¬ìš©
    String userMessage,
    String? appVoiceIdForPrompt, // App-specific voice ID to tailor system prompt
  ) async {
    if (_chatModel == null) {
      throw Exception("Chat model is not initialized. Cannot generate response.");
    }
    try {
      final systemMessage = SystemChatMessage(
        content: _generateSystemPrompt(appVoiceIdForPrompt ?? 'default'),
      );
      List<ChatMessage> history = messageHistory.map((message) {
        if (message.sender == app_models.MessageSender.user) { // app_models.MessageSenderë¡œ ëª…ì‹œì  ì‚¬ìš©
          return HumanChatMessage(content: message.content);
        } else {
          return AIChatMessage(content: message.content);
        }
      }).toList();
      history.add(HumanChatMessage(content: userMessage));
      final messages = [systemMessage, ...history];
      final result = await _chatModel!.call(messages);
      return result.content;
    } catch (e) {
      debugPrint("Error calling LangChain model: $e");
      throw Exception('LangChain í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e');
    }
  }

  Future<List<app_models.Message>> _getConversationHistory(String conversationId) async { // app_models.Messageë¡œ ëª…ì‹œì  ì‚¬ìš©
    final messagesStream = _conversationService.getConversationMessages(conversationId);
    final messages = await messagesStream.first;
    return messages.length > 10 ? messages.sublist(messages.length - 10) : messages;
  }

  String _generateSystemPrompt(String voiceId) {
    switch (voiceId) {
      case 'male_1':
        return '''
ë‹¹ì‹ ì€ ì •ì„œì  ì§€ì›ê³¼ ê³µê°ì„ ì œê³µí•˜ëŠ” ìƒë‹´ AIì…ë‹ˆë‹¤.
ì°¨ë¶„í•˜ê³  ì‹ ì¤‘í•œ ë‚¨ì„± ìƒë‹´ì‚¬ì˜ ì„±ê²©ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°ì •ì— ê³µê°í•˜ê³ , ë¬¸ì œ í•´ê²°ì— ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ëŒ€í™”í•˜ë˜, í•­ìƒ ê³µê°ì ì¸ íƒœë„ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
''';
      case 'child_1':
        return '''
ë‹¹ì‹ ì€ ì •ì„œì  ì§€ì›ê³¼ ê³µê°ì„ ì œê³µí•˜ëŠ” ìƒë‹´ AIì…ë‹ˆë‹¤.
ì¹œê·¼í•˜ê³  ë°ì€ ì„±ê²©ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
ê°„ë‹¨í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ë©°, ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•˜ì„¸ìš”.
ì‚¬ìš©ìë¥¼ ê²©ë ¤í•˜ê³  ê¸ì •ì ì¸ ì—ë„ˆì§€ë¥¼ ì „ë‹¬í•˜ì„¸ìš”.
''';
      case 'calm_1':
        return '''
ë‹¹ì‹ ì€ ì •ì„œì  ì§€ì›ê³¼ ê³µê°ì„ ì œê³µí•˜ëŠ” ìƒë‹´ AIì…ë‹ˆë‹¤.
ì°¨ë¶„í•˜ê³  ë”°ëœ»í•œ ì—¬ì„± ìƒë‹´ì‚¬ì˜ ì„±ê²©ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
ê¹Šì€ ê³µê°ê³¼ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ê°ì •ì„ ì¸ì •í•˜ê³  ìˆ˜ìš©í•˜ì„¸ìš”.
ëª…ìƒê³¼ ë§ˆìŒì±™ê¹€ ê´€ì ì—ì„œ ë„ì›€ì´ ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
''';
      default: // 'default'
        return '''
ë‹¹ì‹ ì€ ì •ì„œì  ì§€ì›ê³¼ ê³µê°ì„ ì œê³µí•˜ëŠ” ìƒë‹´ AIì…ë‹ˆë‹¤.
ë”°ëœ»í•˜ê³  ì¹œì ˆí•œ ì—¬ì„± ìƒë‹´ì‚¬ì˜ ì„±ê²©ìœ¼ë¡œ ëŒ€í™”í•©ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ê°ì •ì— ê³µê°í•˜ê³ , ì‹¬ë¦¬ì  ì•ˆì •ê°ì„ ì£¼ëŠ” ëŒ€í™”ë¥¼ í•˜ì„¸ìš”.
ê¸ì •ì ì´ê³  ì§€ì§€ì ì¸ íƒœë„ë¡œ ì‚¬ìš©ìê°€ ìì‹ ì˜ ê°ì •ì„ í‘œí˜„í•˜ë„ë¡ ê²©ë ¤í•˜ì„¸ìš”.
ëŒ€í™”ëŠ” ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ê³ , ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ ì‘ë‹µí•˜ì„¸ìš”.
''';
    }
  }

  String _getDummyResponse(String userMessage) {
    if (userMessage.contains('ì•ˆë…•') || userMessage.contains('ë°˜ê°€ì›Œ')) {
      return 'ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì‹ ê°€ìš”? ë¬´ìŠ¨ ì¼ì´ ìˆìœ¼ì…¨ë‚˜ìš”?';
    } else if (userMessage.contains('ìŠ¬í¼') || userMessage.contains('ìš°ìš¸í•´')) {
      return 'ê·¸ëŸ° ê°ì •ì´ ë“œì…¨êµ°ìš”. ìŠ¬í””ì„ ëŠë¼ëŠ” ê²ƒì€ ìì—°ìŠ¤ëŸ¬ìš´ ì¼ì´ì—ìš”. ì–´ë–¤ ì¼ì´ ìˆìœ¼ì…¨ëŠ”ì§€ ë” ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”?';
    } else if (userMessage.contains('í™”ê°€ ë‚˜') || userMessage.contains('ì§œì¦')) {
      return 'í™”ê°€ ë‚˜ì…¨êµ°ìš”. ê·¸ëŸ° ê°ì •ì´ ë“œëŠ” ê²ƒì€ ì •ìƒì ì¸ ë°˜ì‘ì´ì—ìš”. ì–´ë–¤ ìƒí™©ì´ ê·¸ëŸ° ê°ì •ì„ ë¶ˆëŸ¬ì¼ìœ¼ì¼°ë‚˜ìš”?';
    } else {
      return 'ë§ì”€í•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤. ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆì„ê¹Œìš”? ì–´ë–¤ ê°ì •ì´ ëŠê»´ì§€ì‹œë‚˜ìš”?';
    }
  }

  Future<Map<String, dynamic>> analyzeSentimentWithLangChain(String text) async {
    if (_chatModel == null || _openAIapiKey.isEmpty) {
      debugPrint("LangchainService: No chat model for sentiment analysis. Using test sentiment.");
      final score = _getTestSentimentScore(text);
      final label = score > 0 ? 'positive' : score < 0 ? 'negative' : 'neutral';
      return {
        'score': score,
        'label': label,
        'emotionType': _getTestEmotionType(text),
        'confidence': 0.7,
      };
    }
    try {
      const template = """
ë‹¤ìŒ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš”:

í…ìŠ¤íŠ¸: {text}

ê²°ê³¼ëŠ” ë‹¤ìŒ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤:
{{
  "score": [-1.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ìˆ«ì, 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê¸ì •ì ],
  "label": ["positive", "neutral", "negative" ì¤‘ í•˜ë‚˜],
  "emotionType": [ì£¼ìš” ê°ì • ìœ í˜• - "joy", "sadness", "anger", "fear", "surprise", "disgust", "neutral" ì¤‘ í•˜ë‚˜],
  "confidence": [0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„]
}}
""";
      final promptTemplate = PromptTemplate.fromTemplate(template);
      final prompt = promptTemplate.format({'text': text});
      final chatPrompt = [
        const SystemChatMessage(content: "You are a sentiment analysis expert. Analyze the sentiment in the given text and return the result in the specified JSON format."),
        HumanChatMessage(content: prompt)
      ];
      final result = await _chatModel!.call(chatPrompt);
      return _extractJsonFromString(result.content);
    } catch (e) {
      debugPrint("Error during sentiment analysis with LangChain: $e");
      throw Exception('ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: $e');
    }
  }

  Map<String, dynamic> _extractJsonFromString(String text) {
    try {
      final regex = RegExp(r'{[\s\S]*}');
      final match = regex.firstMatch(text);
      if (match != null) {
        final jsonStr = match.group(0);
        if (jsonStr != null) return jsonDecode(jsonStr);
      }
      return {'score': 0.0, 'label': 'neutral', 'emotionType': 'neutral', 'confidence': 0.5, 'error': 'Failed to parse JSON from LLM response'};
    } catch (e) {
      debugPrint("Error extracting JSON from string: $e, String: $text");
      return {'score': 0.0, 'label': 'neutral', 'emotionType': 'neutral', 'confidence': 0.5, 'error': e.toString()};
    }
  }

  double _getTestSentimentScore(String text) {
    final positiveWords = ['í–‰ë³µ', 'ê¸°ì¨', 'ì¢‹ì•„', 'ê°ì‚¬', 'ì¦ê±°ì›€', 'í¬ë§'];
    final negativeWords = ['ìŠ¬í””', 'ìš°ìš¸', 'í™”ë‚¨', 'ë¶ˆì•ˆ', 'ê±±ì •', 'ë‘ë ¤ì›€', 'ë¬´ì„œì›€'];
    double score = 0.0;
    for (final word in positiveWords) if (text.contains(word)) score += 0.1;
    for (final word in negativeWords) if (text.contains(word)) score -= 0.1;
    return score.clamp(-1.0, 1.0);
  }

  String _getTestEmotionType(String text) {
    if (text.contains('í–‰ë³µ') || text.contains('ê¸°ì¨') || text.contains('ì¢‹ì•„')) return 'joy';
    if (text.contains('ìŠ¬í””') || text.contains('ìš°ìš¸')) return 'sadness';
    if (text.contains('í™”ë‚¨') || text.contains('ì§œì¦')) return 'anger';
    if (text.contains('ë¶ˆì•ˆ') || text.contains('ê±±ì •') || text.contains('ë‘ë ¤ì›€')) return 'fear';
    if (text.contains('ë†€ë¼')) return 'surprise';
    if (text.contains('ì—­ê²¨') || text.contains('í˜ì˜¤')) return 'disgust';
    return 'neutral';
  }
}